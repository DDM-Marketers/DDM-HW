---
title: "Assignment 6: Churn Management"
author: "GÃ¼nter J. Hitsch"
date: "May 22, 2020"
output:
  pdf_document:
    number_sections: yes
    toc: yes
urlcolor: blue
graphics: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, eval = FALSE,
                      fig.width = 4.5, fig.height = 3.6, fig.align = "right")
```

\setlength{\parskip}{6pt}
\newpage




# Overview

Cell2Cell is a wireless telecom company (the name was changed to disguise the exact identity). As part of its various CRM programs, Cell2Cell actively mitigates customer churn. For this purpose, we develop a model to predict customer churn at Cell2Cell and use the insights from the model to develop a targeted incentive plan to lower the churn rate.

Address these key issues:

1. Is customer churn at Cell2Cell predictable from the customer information that Cell2Cell maintains?

2. What factors drive customer churn? Which factors are particularly important?

3. What incentives should Cell2Cell offer to prevent customer churn?

\newpage




# Data

**Oversampling**

The calibration sample was selected using oversampling, however the validation sample was not created using oversampling and represents the true churn rate in the date. This section we will compare and contrast the churn Rate in the training sample and validation sample. 

```{r}
library(tidyverse)

estimation_df = na.omit(cell2cell_df[cell2cell_df$calibrat == 1, ])

validation_df = na.omit(cell2cell_df[cell2cell_df$calibrat == 0, ])

pv = mean(validation_df$churn)

pe = mean(estimation_df$churn)

print(pv)

print(pe)
```
The churn rate in the training sample is 49.8%, close to 50%, but the true churn rate in the validation sample is much lower, at 1.93%. This verifies that approximately 50% of observations in the training sample take the value 1, contrasted with the true churn rate in the valiation sample. 
\newpage




# Model estimation

In this section, we will develop a logistic regression model to predict the conditional (on the customer attributes) churn probability. The model uses the traning sample only and excluded `customer` and `calibrat` as independent variables. 

```{r}
library(broom)
library(knitr)

fit_logistic = estimation_df[,c(-1, -2)] %>% 
                glm(churn ~ ., data = ., family = "binomial")

estimation_results_df = as.data.frame(tidy(fit_logistic))

kable(estimation_results_df[estimation_results_df$p.value <= 0.05,], digits = 5,
      col.names = c("variable", "estimate", "se", "z-statistic", "p-value"))

validation_predict_df = predict(fit_logistic, validation_df[,c(-1, -2)], type = "response")

mean(validation_predict_df)
```

\medskip

The churn rate predicted in the validation sample is 0.4772. The following independent variables are significant with 95% confidence. 


\newpage



# Model estimation and prediction: Accounting for oversampling

In the section we will add an offset variable to de-bias the predicted response. 
(1) Create the offset variable

```{r}

offset_var = (log(pe) - log(1-pe)) - (log(pv) - log(1-pv))

print(offset_var)
```
The offset variable is 3.920892.

(2) Add the offset as a new column to the estimation sample and estimate the logistic regression model.

```{r}
    
estimation_df$offset_var = offset_var   
    
fit_logistic = estimation_df[,c(-1, -2)] %>% 
                glm(churn ~ . + offset(offset_var), data = ., family = "binomial")
    
summary(fit_logistic)
```
    
(3) Set the offset variable `offset_var` to 0 and add it to the validation sample. Then calculate the predicted churn rates after de-biasing. 

```{r, warning = FALSE}

validation_df$offset_var = 0
    
validation_predict_df = predict(fit_logistic, validation_df[,c(-1, -2)], type = "response")

mean(validation_predict_df)

pv

```
The mean of the predicted churn rates is 0.0194, which is very close to the observed average churn rate in the validation sample (0.0193). 

\newpage




# Model validation

(1) Create a table that contains both the observed `churn` and the predicted churn rate (probability) from the logistic regression model.

```{r}

compare = validation_df[, "churn"]

compare = cbind(compare, validation_predict_df)

compare =data.frame(compare)

names(compare)[1] <- "churn"
names(compare)[2] <- "predict"

```

(2) Add a column, `score`, that assigns a number from 1 to 10 to each customer based on the predicted churn rate. 

```{r}

compare$score = cut_number(compare$predict, n = 10, labels = FALSE)

head(compare)

```

(3) Create a summary table that, for each of the scores, contains:
    
```{r}    

compare_score = compare %>% 
  group_by(score) %>% 
  summarize(ob_churn = mean(churn),
            pr_churn = mean(predict),
            lift = 100*ob_churn/pv)
 
compare_score
```    

(4) Provide a graph that displays score-level mean observed churn on the y-axis and the customer `score` on the x-axis.

```{r}

library("ggplot2")

compare_score %>% 
ggplot(aes(x = score, y = ob_churn), data = .) + geom_point() + geom_line() + theme_bw()

```

(5) Similarly, provide a lift chart (graph).

```{r}

compare_score %>% 
ggplot(aes(x = score, y = lift), data = .) + geom_point() + geom_line() + theme_bw()

```

(6) Display the data in (4) and (5) in the form of a table.

```{r}
compare_score[-3]
```

\medskip

Discuss the results. Do the results provide evidence for the validity of the model?
The results provide evidence for the validity of the model. Because the lift factors have an upward trend, rather than a horizontal line at 100. That means our model can effectively predict the different churn probabilities for different customers. 
But the model also has limitations because we found that when the customer did churn, our model is not very accurate in predicting churn = 1, but it performed better in predicting customers who didn't churn. 

```{r}

compare %>% 
ggplot(aes(x = churn, y = predict, group = churn, color = churn), data = .) + geom_boxplot( )

```

\newpage




# Effect sizes: Why do customers churn?

We would like to understand *why* customers churn, which can help us to propose incentives to prevent customer churn. Hence, we now construct a table that contains comparable effect sizes (changes in the churn probability) for all independent variables, as we discussed in class.

Because logistic regression coefficients are not directly interpretable, we first need to estimate a linear probability model that predicts customer churn.

Note: Do *not* use an offset variable when estimating the linear probability model!

Once you have estimated the model, you can construct the effect size table in Excel, or you can use the code below to construct the table in an automated fashion

\medskip


## Construct effect size table in Excel

Assuming your linear probability model output is called `fit_linear_prob`, you can convert the estimation results into a data frame and then save the estimation results as a csv file:

```{r}

fit_linear_prob = estimation_df[,c(-1, -2, -70)] %>% 
                lm(churn ~ ., data = .)

linear_prob_results_df = as.data.frame(tidy(fit_linear_prob))
write_csv(linear_prob_results_df, path = "Assign6_export.csv")


```

Now proceed in Excel, using both the `Cell2Cell-Database-Documentation.xlsx` file and the estimation results files.

\medskip


## Automated approach to construct effect size table

Run all four code chunks below.

For the code to work ensure that:

(i) Your main data frame, `cell2cell_df`, is in memory, and you have removed all rows with missing values.

```{r}
cell2cell_df = na.omit(cell2cell_df)
```

(ii) Either the estimation results object from the linear probability model is called `fit_linear_prob`, or you modify the object name in the third code chunk below.

(iii) The objects `p_e` and `p_v` that contain the mean observed churn rates in the estimation and validation samples are in memory.

```{r}
p_e = pe
p_v = pv
```

If these conditions are met, the code below will work.

\newpage


First, we create the function `isDummy` that returns the value 1 if `x` is a dummy variable, and 0 otherwise.

```{r}
isDummy <- function(x) {
   elements = unique(x)
   if (length(elements) == 2L & all(elements %in% c(0L,1L))) is_dummy = TRUE
   else is_dummy = FALSE
   return(is_dummy)
}
```


Second, we create `summary_df`, which contains the standard deviation of all variables and an indicator, `is_dummy = 1`, if the variable is a dummy variable.

```{r}
summary_df = cell2cell_df %>%
   summarize_all(list(sd = sd, is.dummy = isDummy)) %>%
   pivot_longer(cols = everything(),
                names_to = "statistic", values_to = "value") %>%
   separate(statistic, into = c("variable", "statistic"), sep = "_") %>%
   pivot_wider(id_cols = variable, names_from = "statistic", values_from = "value") %>%
   rename(is_dummy = is.dummy)
```


Third, we create the `effect_sizes_df` table that combines the estimation results (in the object `fit_linear_prob`) and the summary statistics.

```{r}
effect_sizes_df = as.data.frame(tidy(fit_linear_prob)) %>%
   transmute(variable = term, estimate = estimate, t_stat = statistic) %>%
   inner_join(summary_df) %>%
   mutate(change_prob = ifelse(is_dummy, estimate, estimate*sd)*(p_v/p_e)*100)
```


Fourth, we sort the variables according to the magnitude of the effect sizes, and print the results table using `kable`.

```{r}
effect_sizes_df = effect_sizes_df %>%
   arrange(desc(abs(change_prob)))

kable(effect_sizes_df, digits = 4)
```


Alternatively, you can write the effect size table to a csv file:

```{r}
write_csv(effect_sizes_df, path = "Assign6_export2.csv")
```

\medskip

**Interpretation of the `change_prob` variable**: For a dummy variable, `change_prob` is the change in the churn probability associated with an increase in the dummy value from 0 to 1. For all other variables, `change_prob` is the change in the churn probability associated with an increse in the value of the variable by one standard deviation.

`change_prob` is defined on the scale from 0 to 100. I.e., if `change_prob` takes the value 0.6, the effect size is a change in the churn probability by 0.6%, not by 60%!

```{r}
library(gamlr)

y = cell2cell_df$churn

x = cell2cell_df[, c(-1, -2, -3)]

cv.fit <- cv.gamlr(x, y,
				   lambda.min.ratio=1e-3,
				   family="binomial",
				   verb=TRUE)

plot(cv.fit$gamlr)

plot(cv.fit)

c = drop(coef(cv.fit, select="min"))

c[abs(c) > 0.2]

#creditaa, refurb, retcall are most strong and stable
#check causal about refurb, retcall and creditaa with double lasso

#creditaa
d1 = x[, 32]
#refurb
d2 = x[, 36]
#retcall
d3 = x[, 66]

x = x[, c(-32, -36, -66)]

#double lasso for creditaa

treat1 <- gamlr(x,d1,lambda.min.ratio=1e-4, family = "binomial")

plot(treat1)

d1hat <- predict(treat1, x, type="response") 

d1hat = drop(d1hat)

cor(d1hat, d1)^2

causal1 <- gamlr(cBind(d1,d1hat,x),y,free=2,lmr=1e-4, , family = "binomial")

coef(causal1)["d1",]
#which is not 0, so creditaa is causal

#double lasso for refurb

treat2 <- gamlr(x,d2,lambda.min.ratio=1e-4, family = "binomial")

plot(treat2)

d2hat <- predict(treat2, x, type="response") 

d2hat = drop(d2hat)

cor(d2hat, d2)^2

causal2 <- gamlr(cBind(d2,d2hat,x),y,free=2,lmr=1e-4, , family = "binomial")

coef(causal2)["d2",]
#which is not 0, so refurb is causal

#double lasso for retcall

treat3 <- gamlr(x,d3,lambda.min.ratio=1e-4, family = "binomial")

#plot(treat3)

d3hat <- predict(treat3, x, type="response") 

d3hat = drop(d3hat)

cor(d3hat, d3)^2
#prefect cover

causal3 <- gamlr(cBind(d3,d3hat,x),y,free=2,lmr=1e-4, , family = "binomial")

coef(causal3)["d3",]
#it is 0, so retcall is not causal

coef(treat3)
#the retcall is covered by retcalls.

```

\newpage




# Develop incentives to prevent churn

Using the effect size table that you constructed in the previous section, identify some factors that are strongly associated with churn. If actionable, propose an incentive that can be targeted to the customers to prevent churn.

\newpage




# Summarize your main results

1. Is customer churn at Cell2Cell predictable from the customer information that Cell2Cell maintains?

2. What factors drive customer churn? Which factors are particularly important?

3. What incentives should Cell2Cell offer to prevent customer churn?



