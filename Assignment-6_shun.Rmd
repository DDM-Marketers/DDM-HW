---
title: "Assignment 6: Churn Management"
author: "Group 11: Christina Wang, Kailin Fu, Shun Guan, Sylvia Lu, Yiran Huang"
date: "May 28, 2020"
output:
  pdf_document:
    number_sections: yes
    toc: yes
urlcolor: blue
graphics: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, eval = TRUE,
                      fig.width = 4.5, fig.height = 3.6, fig.align = "right")
```

\setlength{\parskip}{6pt}
\newpage




# Overview

Cell2Cell is a wireless telecom company (the name was changed to disguise the exact identity). As part of its various CRM programs, Cell2Cell actively mitigates customer churn. For this purpose, we develop a model to predict customer churn at Cell2Cell and use the insights from the model to develop a targeted incentive plan to lower the churn rate.

Address these key issues:

1. Is customer churn at Cell2Cell predictable from the customer information that Cell2Cell maintains?

2. What factors drive customer churn? Which factors are particularly important?

3. What incentives should Cell2Cell offer to prevent customer churn?

```{r, include = TRUE}
    library(ggplot2)
    library(tidyverse)
    library(dplyr)
    library(tidyr)
    library(lfe)
    load('Cell2Cell.RData')
```

\newpage




# Data

**Oversampling**

The calibration sample was selected using oversampling, however the validation sample was not created using oversampling and represents the true churn rate in the date. This section we will compare and contrast the churn Rate in the training sample and validation sample. 

```{r}
library(tidyverse)

estimation_df = na.omit(cell2cell_df[cell2cell_df$calibrat == 1, ])

validation_df = na.omit(cell2cell_df[cell2cell_df$calibrat == 0, ])

pv = mean(validation_df$churn)

pe = mean(estimation_df$churn)

print(pv)

print(pe)
```
The churn rate in the training sample is 49.8%, close to 50%, but the true churn rate in the validation sample is much lower, at 1.93%. This verifies that approximately 50% of observations in the training sample take the value 1, contrasted with the true churn rate in the valiation sample. 
\newpage




# Model estimation

In this section, we will develop a logistic regression model to predict the conditional (on the customer attributes) churn probability. The model uses the traning sample only and excluded `customer` and `calibrat` as independent variables. 

```{r}
library(broom)
library(knitr)

fit_logistic = estimation_df[,c(-1, -2)] %>% 
                glm(churn ~ ., data = ., family = "binomial")

estimation_results_df = as.data.frame(tidy(fit_logistic))

kable(estimation_results_df[estimation_results_df$p.value <= 0.05,], digits = 5,
      col.names = c("variable", "estimate", "se", "z-statistic", "p-value"))

validation_predict_df = predict(fit_logistic, validation_df[,c(-1, -2)], type = "response")

mean(validation_predict_df)
```

\medskip

The churn rate predicted in the validation sample is 0.4772. The following independent variables are significant with 95% confidence. 


\newpage



# Model estimation and prediction: Accounting for oversampling

(1) Create the offset variable

```{r}

offset_var = (log(pe) - log(1-pe)) - (log(pv) - log(1-pv))

print(offset_var)
```
The offset variable is 3.920892.

(2) Add the offset as a new column to the estimation sample and estimate the logistic regression model.

```{r}
    
estimation_df$offset_var = offset_var   
    
fit_logistic = estimation_df[,c(-1, -2)] %>% 
                glm(churn ~ . + offset(offset_var), data = ., family = "binomial")
    
summary(fit_logistic)
```
    
(3) Set the offset variable `offset_var` to 0 and add it to the validation sample. Then calculate the predicted churn rates after de-biasing. 

```{r, warning = FALSE}

validation_df$offset_var = 0
    
validation_predict_df = predict(fit_logistic, validation_df[,c(-1, -2)], type = "response")

c(churn_rate = pv, churn_rate_pred = mean(validation_predict_df), error_rate = (mean(validation_predict_df)-pv)/pv)
```
The mean of the predicted churn rates is 0.0194, which is very close to the observed average churn rate in the validation sample (0.0193). 

\newpage




# Model validation

(1) Create a table that contains both the observed `churn` and the predicted churn rate (probability) from the logistic regression model.

```{r}

compare = validation_df[, "churn"]

compare = cbind(compare, validation_predict_df)

compare =data.frame(compare)

names(compare)[1] <- "churn"
names(compare)[2] <- "predict"

```

(2) Add a column, `score`, that assigns a number from 1 to 10 to each customer based on the predicted churn rate. 

```{r}

compare$score = cut_number(compare$predict, n = 10, labels = FALSE)

head(compare)

```

(3) Create a summary table that for each of the scores, containing mean predicted churn rate, mean observed churn rate, and lift factor. 
    
```{r}    

compare_score = compare %>% 
  group_by(score) %>% 
  summarize(ob_churn = mean(churn),
            pr_churn = mean(predict),
            lift = 100*ob_churn/pv)
 
compare_score
```    

(4) Provide a graph that displays score-level mean observed churn on the y-axis and the customer `score` on the x-axis.

```{r}

library("ggplot2")

compare_score %>% 
ggplot(aes(x = score, y = ob_churn), data = .) + geom_point() + geom_line() + theme_bw()

```

(5) Provide a lift chart (graph).

```{r}

compare_score %>% 
ggplot(aes(x = score, y = lift), data = .) + geom_point() + geom_line() + theme_bw()

```

(6) Display the data in (4) and (5) in the form of a table.

```{r}
compare_score[-3]
```

```{r}

compare %>% 
ggplot(aes(x = churn, y = predict, group = churn, color = churn), data = .) + geom_boxplot( )

```
\medskip

The results provide evidence for the validity of the model. Because the lift factors have an upward trend, rather than a horizontal line at 100. That means our model can effectively predict the different churn probabilities for different customers. 
But the model also has limitations because we found that when the customer did churn, our model is not very accurate in predicting churn = 1, but it performed better in predicting customers who didn't churn. 
\newpage




# Effect sizes: Why do customers churn?

In this section we will convert the estimation results into a data frame and then save the estimation results as a csv file:

```{r}

fit_linear_prob = estimation_df[,c(-1, -2, -70)] %>% 
                lm(churn ~ ., data = .)

linear_prob_results_df = as.data.frame(tidy(fit_linear_prob))
write_csv(linear_prob_results_df, path = "Assign6_export.csv")


```

\medskip


## Automated approach to construct effect size table

We will remove missing values in the data frame and check the objects `p_e` and `p_v` that contain the mean observed churn rates in the estimation and validation samples are in memory.

```{r}
cell2cell_df = na.omit(cell2cell_df)
```

```{r}
p_e = pe
p_v = pv
```

\newpage


First, we create the function `isDummy` that returns the value 1 if `x` is a dummy variable, and 0 otherwise.

```{r}
isDummy <- function(x) {
   elements = unique(x)
   if (length(elements) == 2L & all(elements %in% c(0L,1L))) is_dummy = TRUE
   else is_dummy = FALSE
   return(is_dummy)
}
```


Second, we create `summary_df`, which contains the standard deviation of all variables and an indicator, `is_dummy = 1`, if the variable is a dummy variable.

```{r}
summary_df = cell2cell_df %>%
   summarize_all(list(sd = sd, is.dummy = isDummy)) %>%
   pivot_longer(cols = everything(),
                names_to = "statistic", values_to = "value") %>%
   separate(statistic, into = c("variable", "statistic"), sep = "_") %>%
   pivot_wider(id_cols = variable, names_from = "statistic", values_from = "value") %>%
   rename(is_dummy = is.dummy)
```


Third, we create the `effect_sizes_df` table that combines the estimation results (in the object `fit_linear_prob`) and the summary statistics.

```{r}
effect_sizes_df = as.data.frame(tidy(fit_linear_prob)) %>%
   transmute(variable = term, estimate = estimate, t_stat = statistic) %>%
   inner_join(summary_df) %>%
   mutate(change_prob = ifelse(is_dummy, estimate, estimate*sd)*(p_v/p_e)*100)
```


Fourth, we sort the variables according to the magnitude of the effect sizes, and print the results table using `kable`.

```{r}
effect_sizes_df = effect_sizes_df %>%
   arrange(desc(abs(change_prob)))

kable(effect_sizes_df, digits = 4)
```


Alternatively, you can write the effect size table to a csv file:

```{r}
write_csv(effect_sizes_df, path = "Assign6_export2.csv")
```

\medskip



```{r}
library(gamlr)

y = cell2cell_df$churn

x = cell2cell_df[, c(-1, -2, -3)]

cv.fit <- cv.gamlr(x, y,
				   lambda.min.ratio=1e-3,
				   family="binomial",
				   verb=TRUE)

plot(cv.fit$gamlr)

plot(cv.fit)

c = drop(coef(cv.fit, select="min"))

c[abs(c) > 0.2]

#creditaa, refurb, retcall are most strong and stable
#check causal about refurb, retcall and creditaa with double lasso

#creditaa
d1 = x[, 32]
#refurb
d2 = x[, 36]
#retcall
d3 = x[, 66]

x = x[, c(-32, -36, -66)]

#double lasso for creditaa

treat1 <- gamlr(x,d1,lambda.min.ratio=1e-4, family = "binomial")

plot(treat1)

d1hat <- predict(treat1, x, type="response") 

d1hat = drop(d1hat)

cor(d1hat, d1)^2

causal1 <- gamlr(cBind(d1,d1hat,x),y,free=2,lmr=1e-4, , family = "binomial")

#coef(causal1)["d1",]
#which is not 0, so creditaa is causal

#double lasso for refurb

treat2 <- gamlr(x,d2,lambda.min.ratio=1e-4, family = "binomial")

plot(treat2)

d2hat <- predict(treat2, x, type="response") 

d2hat = drop(d2hat)

cor(d2hat, d2)^2

causal2 <- gamlr(cBind(d2,d2hat,x),y,free=2,lmr=1e-4, , family = "binomial")

#coef(causal2)["d2",]
#which is not 0, so refurb is causal

#double lasso for retcall

treat3 <- gamlr(x,d3,lambda.min.ratio=1e-4, family = "binomial")

#plot(treat3)

d3hat <- predict(treat3, x, type="response") 

d3hat = drop(d3hat)

cor(d3hat, d3)^2
#prefect cover

causal3 <- gamlr(cBind(d3,d3hat,x),y,free=2,lmr=1e-4, , family = "binomial")

#coef(causal3)["d3",]
#it is 0, so retcall is not causal

coef(treat3)
#the retcall is covered by retcalls.

```

\newpage




# Develop incentives to prevent churn

Using the effect size table that you constructed in the previous section, identify some factors that are strongly associated with churn. If actionable, propose an incentive that can be targeted to the customers to prevent churn.

From the effect size table, the following variables are strongly associated with churn: 'retcall', 'creditaa', 'eqpdays', 'refurbs' and 'months'. To target customers that have made a call to retention team, we can offer pricing discounts to keep within our wireless network. To target customers with refurbished handset, we can offer extended warranty to improve their customer experience. To target customers with lower credit ratings, we can offer them extended payment terms to help them meet the payment deadline. 

\newpage




# Summarize your main results

1. Is customer churn at Cell2Cell predictable from the customer information that Cell2Cell maintains?

Customer churn at Cell2Cell is predictable but not accurate from the customer information that Cell2Cell maintains. The churn rate is predicted with an error rate of 0.7%, relatively accurate. However, the false negative rate is high, where the model predicts low churn probability for positive churns (churn = 1). The false positive rate is low numerically, but is high comparing to the churn rate. The model would be of low sensitivity (true positive rate) and high specificity, while the high specificity is from the high base non-churn rate not the model accuracy.

The model can be used to roughly test the factor importance but not to predict exact customers' churn probability. Better model techniques are needed with variable selections to predict the churns.

\medskip

2. What factors drive customer churn? Which factors are particularly important?

From the change probability ranking, the top five factors are 'retcall', 'creditaa', 'eqpdays', 'refurbs' and 'months', excluding the ones with low t values (greater than -2 and smaller than 2). The variable importance are also tested and the top three are 'retcall', 'creditaa' and 'refurbs' (per results and plots from section 6.2).

The causality is tested for each of them by double lasso. The factors 'creditaa' and 'refurbs' are causal. The factor 'retcall' is not causal, but highly correlated to 'retcalls'. Variable selection is needed to further improve the model.

\medskip

3. What incentives should Cell2Cell offer to prevent customer churn?

Cell2Cell need to offer customers more promotions proactively to prevent them from thinking to churn. Once they start to think of churning to call to the retention team, they are much more likely to churn. When they call, Cell2Cell need to offer more promotions, discounts or extra benefits to prevent them from churning.

Customer segmentation is needed to specifity more targeted strategies to different customers. For high credit rating customers, they are much less likely to churn than normal credit rating customers (change_prob(creditaa) ranking second). Cell2Cell needs to offer more promotions or benefits to the lower credit rating customers than higher. Same for customers buying refurbished devices, longer warranties and discounts would be beneficial to prevent them from churning.


